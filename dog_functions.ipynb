{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOU1l04ntAL+o2IGxVKK22V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dovkess/FGCVBreedDetection/blob/main/dog_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import cell. this is a cell run once to avoid having import problems later on.\n",
        "!pip install tensorflow\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import VGG19, InceptionResNetV2, InceptionV3, NASNetLarge\n",
        "from tensorflow.keras.applications import ConvNeXtXLarge, ResNet152V2, Xception, DenseNet201, EfficientNetV2L\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import time\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import threading\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "%pip install lime\n",
        "import lime\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "!pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "id": "3FL54qtRWUkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_data_from_drive(drive_loc, local_loc='Images'):\n",
        "    '''\n",
        "    Copy data from drive to local machine\n",
        "    Expecting the data to be folder\n",
        "\n",
        "    Args:\n",
        "        drive_loc (str): path to the folder in drive\n",
        "        local_loc (str): path to the folder in local machine\n",
        "    '''\n",
        "    print(time.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
        "    base_path = '/content/{}'.format(local_loc)\n",
        "    %cp -r {drive_loc} {base_path}\n",
        "    print(time.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n"
      ],
      "metadata": {
        "id": "lspSezaJruxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_file_thread(source, target):\n",
        "    '''\n",
        "    Copy file from source to target in a separate thread\n",
        "\n",
        "    Args:\n",
        "        source (str): path to the source file\n",
        "        target (str): path to the target file\n",
        "    '''\n",
        "    shutil.copy(source, target)\n",
        "\n",
        "def copy_images_by_list(file_names, drive_location, local_loc='Images'):\n",
        "    '''\n",
        "    Copy images from drive to local machine\n",
        "    Expecting the data to be in a folder\n",
        "\n",
        "    Args:\n",
        "        file_names (list): list of file names to copy\n",
        "        drive_location (str): path to the folder in drive\n",
        "        local_loc (str): path to the folder in local machine\n",
        "    '''\n",
        "    local_dir = '/content/'+local_loc\n",
        "    folders = set([f.split('/')[0] for f in file_names])\n",
        "    # create sub directories\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(local_dir, folder)\n",
        "        if not os.path.isdir(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "    print(time.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
        "    # Copy the images\n",
        "    for e, f in enumerate(file_names):\n",
        "        drive_path = os.path.join(drive_location, f)\n",
        "        local_path = os.path.join(local_dir, f)\n",
        "        threading.Thread(target=copy_file_thread, args=(drive_path, local_path)).start()\n",
        "        # Sleep to allow the threads to complete the work and avoid threshing.\n",
        "        if e % 500 == 0:\n",
        "            time.sleep(5)\n",
        "    print(time.strftime(\"%Y-%m-%d_%H:%M:%S\"))"
      ],
      "metadata": {
        "id": "4ieIbMvSzQem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================= CREATE DATA SETS =========================== #\n",
        "def create_data_sets(base_path, batch_size, validation_split, classes, train=True, input_size=[331, 331]):\n",
        "    '''\n",
        "    Create data sets for training and testing\n",
        "    Args:\n",
        "        base_path (str): path to the folder containing the images\n",
        "        batch_size (int): batch size for each iteration\n",
        "        validation_split (float): percentage of the data to use for validation\n",
        "        classes (list): list of classes\n",
        "        train (bool): whether to create a training set or not\n",
        "        input_size (list): size of the input images\n",
        "\n",
        "    Returns:\n",
        "        train_generator (ImageDataGenerator): training data generator\n",
        "        test_generator (ImageDataGenerator): testing data generator\n",
        "    '''\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.0,\n",
        "        zoom_range=0.0,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        base_path,\n",
        "        target_size=(input_size[0], input_size[1]),\n",
        "        batch_size=batch_size,\n",
        "        subset='training',\n",
        "        classes=classes,\n",
        "        shuffle = True if train else False\n",
        "    )\n",
        "    test_generator = None\n",
        "    if train:\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255, validation_split=validation_split)\n",
        "\n",
        "        test_generator = test_datagen.flow_from_directory(\n",
        "            base_path,\n",
        "            target_size=(input_size[0], input_size[1]),\n",
        "            batch_size=64,\n",
        "            subset='validation',\n",
        "            classes=classes,\n",
        "            shuffle = False\n",
        "        )\n",
        "    return train_generator, test_generator"
      ],
      "metadata": {
        "id": "eQFheffiLUTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================= CREATE SINGLE DATA SET =========================== #\n",
        "\n",
        "def create_single_data_set(base_path, batch_size, classes, shuffle=False, input_size=[331, 331]):\n",
        "    '''\n",
        "    Create data sets for training or testing.\n",
        "\n",
        "    Args:\n",
        "        base_path (str): path to the folder containing the images\n",
        "        batch_size (int): batch size for each iteration\n",
        "        classes (list): list of classes\n",
        "        shuffle (bool): whether to shuffle the data or not\n",
        "        input_size (list): size of the input images\n",
        "\n",
        "    Returns:\n",
        "        data_gen (ImageDataGenerator): data generator\n",
        "    '''\n",
        "    img_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "    )\n",
        "\n",
        "    data_gen = img_datagen.flow_from_directory(\n",
        "        base_path,\n",
        "        target_size=(input_size[0], input_size[1]),\n",
        "        batch_size=batch_size,\n",
        "        classes=classes,\n",
        "        shuffle = shuffle\n",
        "    )\n",
        "    return data_gen"
      ],
      "metadata": {
        "id": "rCkGQnqEDQvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_nasnetlarge_net(class_num, lr):\n",
        "    '''\n",
        "    Define NASNet params for transfer learning.\n",
        "\n",
        "    Args:\n",
        "        class_num (int): number of classes\n",
        "        lr (float): learning rate\n",
        "\n",
        "    Returns:\n",
        "        model (Sequential): model\n",
        "    '''\n",
        "    base_model = NASNetLarge(weights='imagenet', include_top=False, input_shape=(331, 331, 3))\n",
        "\n",
        "    # Freeze base model layers\n",
        "    base_model.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    prediction = Dense(class_num, activation='softmax')\n",
        "    model.add(prediction)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def define_inseption_net(class_num, lr):\n",
        "    # ======================= DEFINE NET InceptionV3 V3 =========================== #\n",
        "    '''\n",
        "    Define InceptionV3 params for transfer learning.\n",
        "\n",
        "    Args:\n",
        "        class_num (int): number of classes\n",
        "        lr (float): learning rate\n",
        "\n",
        "    Returns:\n",
        "        model\n",
        "    '''\n",
        "    base_model_v3 = InceptionV3(weights='imagenet', include_top=False, input_shape=(229, 229, 3))\n",
        "\n",
        "    # Freeze base model layers\n",
        "    base_model_v3.trainable = False\n",
        "    model_v3 = Sequential()\n",
        "    model_v3.add(base_model_v3)\n",
        "    model_v3.add(GlobalAveragePooling2D())\n",
        "    prediction_v3 = Dense(class_num, activation='softmax')\n",
        "    model_v3.add(prediction_v3)\n",
        "\n",
        "    # Compile the model\n",
        "    model_v3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model_v3.summary()\n",
        "    return model_v3\n",
        "\n",
        "def define_ConvNeXtXLarge_net(class_num, lr):\n",
        "    #===================== DEFINE NET ConvNeXtXLarge =============================== #\n",
        "    '''\n",
        "    Define ConvNeXtXLarge params for transfer learning.\n",
        "\n",
        "    Args:\n",
        "        class_num (int): number of classes\n",
        "        lr (float): learning rate\n",
        "\n",
        "    Returns:\n",
        "        model\n",
        "    '''\n",
        "    base_model_convnext = ConvNeXtXLarge(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    # Freeze base model layers\n",
        "    base_model_convnext.trainable = False\n",
        "    model_convnext = Sequential()\n",
        "    model_convnext.add(base_model_convnext)\n",
        "    model_convnext.add(GlobalAveragePooling2D())\n",
        "    prediction_convnext = Dense(class_num, activation='softmax')\n",
        "    model_convnext.add(prediction_convnext)\n",
        "\n",
        "    # Compile model\n",
        "    model_convnext.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model_convnext.summary()\n",
        "    return model_convnext\n",
        "\n",
        "\n",
        "def define_vgg19_net(class_num, lr):\n",
        "    '''\n",
        "    Define vgg19 params for transfer learning.\n",
        "\n",
        "    Args:\n",
        "        class_num (int): number of classes\n",
        "        lr (float): learning rate\n",
        "\n",
        "    Returns:\n",
        "        model\n",
        "    '''\n",
        "    # This net showed performance at the very low range for this problem for both cropped and un cropped (cropped was better)\n",
        "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(class_num, activation='softmax'))\n",
        "    opt = Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def define_resnet152_net(class_num, lr):\n",
        "    '''\n",
        "    Define resnet params for transfer learning.\n",
        "\n",
        "    Args:\n",
        "        class_num (int): number of classes\n",
        "        lr (float): learning rate\n",
        "\n",
        "    Returns:\n",
        "        model\n",
        "    '''\n",
        "    base_model = ResNet152V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(class_num, activation='softmax'))\n",
        "    opt = Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def define_xception_net(class_num, lr):\n",
        "    '''\n",
        "    Define xception params for transfer learning.\n",
        "\n",
        "    Args:\n",
        "        class_num (int): number of classes\n",
        "        lr (float): learning rate\n",
        "\n",
        "    Returns:\n",
        "        model\n",
        "    '''\n",
        "    base_model = Xception(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "    base_model.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(class_num, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def define_densenet201_net(class_num, lr):\n",
        "    '''\n",
        "    Define densenet params for transfer learning.\n",
        "\n",
        "    Args:\n",
        "        class_num (int): number of classes\n",
        "        lr (float): learning rate\n",
        "\n",
        "    Returns:\n",
        "        model\n",
        "    '''\n",
        "    base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(class_num, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def define_efficientnetv2l_net(class_num, lr):\n",
        "    '''\n",
        "    Define efficientnet params for transfer learning.\n",
        "\n",
        "    Args:\n",
        "        class_num (int): number of classes\n",
        "        lr (float): learning rate\n",
        "\n",
        "    Returns:\n",
        "        model\n",
        "    '''\n",
        "    # This net showed performance at the very low range for this problem both\n",
        "    # for cropped and uncropped images (cropped was better)\n",
        "    base_model = EfficientNetV2L(weights='imagenet', include_top=False, input_shape=(384, 384, 3))\n",
        "    base_model.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(class_num, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "-F9iqwYkBDaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_net(model, train_generator, test_generator, snapshot_dir='/content/drive/MyDrive/DogProject/snapshots/', epochs=20):\n",
        "    # ======================= TRAIN THE NET =========================== #\n",
        "    '''\n",
        "    Run transfer learning on a net.\n",
        "\n",
        "    Args:\n",
        "        model (Sequential): model to train\n",
        "        train_generator (ImageDataGenerator): training data generator\n",
        "        test_generator (ImageDataGenerator): testing data generator\n",
        "        snapshot_dir (str): directory to save snapshots\n",
        "        epochs (int): number of epochs to train\n",
        "\n",
        "    '''\n",
        "    checkpoint_filepath = '{}/check{}.keras'.format(snapshot_dir, time.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
        "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "\n",
        "    # Train the model\n",
        "    # Pass the generators directly to model.fit\n",
        "    h = model.fit(train_generator, epochs=epochs, validation_data=test_generator, callbacks=[model_checkpoint_callback]) # Added [] around callback\n",
        "    t = time.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
        "    # Save the model\n",
        "    if not os.path.isdir(snapshot_dir):\n",
        "        os.mkdir(snapshot_dir)\n",
        "    # Save the model in the native Keras format\n",
        "    model.save(os.path.join(snapshot_dir, 'dog_breed_classifier_{}.keras'.format(t)))\n",
        "    # save test file names\n",
        "    names = test_generator.image_filenames if hasattr(test_generator, 'image_filenames') else test_generator.filenames\n",
        "    pickle.dump(names, open('/content/drive/MyDrive/DogProject/test_filenames_{}.pkl'.format(t), 'wb'))\n",
        "    # pickle.dump(test_generator.class_indices, open('/content/drive/MyDrive/MyDrive/DogProject/class_indices_{}.pkl'.format(t), 'wb'))"
      ],
      "metadata": {
        "id": "nt5c2j8jQgWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(model, image_path, class_indices, size=[331, 331], show_five=False, plot_image=False):\n",
        "    '''\n",
        "    Predict the breed of a dog from an image.\n",
        "\n",
        "    Args:\n",
        "        model (Sequential): model to use for prediction\n",
        "        image_path (str): path to the image\n",
        "        class_indices (dict): dictionary mapping class indices to class names\n",
        "        size (list): size of the input image\n",
        "        show_five (bool): whether to show the top 5 predictions\n",
        "        plot_image (bool): whether to draw the image\n",
        "\n",
        "    Returns:\n",
        "        preds (list): list of predictions\n",
        "    '''\n",
        "    resize_and_rescale = tf.keras.Sequential([\n",
        "        keras.layers.Resizing(size[0], size[1]),\n",
        "        keras.layers.Rescaling(1./255)\n",
        "        ])\n",
        "    xs = image.img_to_array(image_path)\n",
        "    xs = resize_and_rescale(xs)\n",
        "    xs = np.expand_dims(xs, axis=0)\n",
        "\n",
        "    # Make predictions\n",
        "    preds = model.predict(xs)\n",
        "    predicted_class_index = np.argmax(preds)\n",
        "\n",
        "    # class_inds = pickle.load(open('/content/drive/MyDrive/DogProject/class_indices.pkl', 'rb'))\n",
        "    class_labels = list(class_indices.keys())\n",
        "    predicted_class = class_labels[predicted_class_index]\n",
        "    print(f\"Predicted dog breed: {predicted_class}\")\n",
        "    if show_five:\n",
        "        top_5_indices = np.argsort(preds[0])[::-1][:5]  # Get indices of top 5 predictions\n",
        "        top_5_probabilities = preds[0][top_5_indices]\n",
        "        top_5_classes = [class_labels[i] for i in top_5_indices]\n",
        "\n",
        "        print(\"Top 5 predictions:\")\n",
        "        for i in range(5):\n",
        "            print(f\"{top_5_classes[i]}: {top_5_probabilities[i]:.4f}\")\n",
        "\n",
        "    if plot_image:\n",
        "        # Display the image\n",
        "        plt.imshow(xs[0])\n",
        "        plt.title(f\"Predicted breed: {predicted_class}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    return preds\n"
      ],
      "metadata": {
        "id": "gUrSpbEnTlxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_conf_mat(model, test_generator):\n",
        "    '''\n",
        "    Create a confusion matrix for a model.\n",
        "\n",
        "    Args:\n",
        "        model (Sequential): model to use for prediction\n",
        "        test_generator (ImageDataGenerator): testing data generator\n",
        "\n",
        "    '''\n",
        "    pred = model.predict(test_generator)\n",
        "    y_pred = pred.argmax(axis=1)\n",
        "    y_true = test_generator.classes\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    plt.figure(figsize=(100, 80))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=list(test_generator.class_indices.keys()),\n",
        "                yticklabels=list(test_generator.class_indices.keys()))\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "pyDbm92LZKGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_worst_pred(cm, class_ind, thresh=6):\n",
        "    '''\n",
        "    Get the classes with the worst predictions in a confusion matrix.\n",
        "\n",
        "    Args:\n",
        "        cm (np.array): confusion matrix\n",
        "        class_ind (list): list of class indices\n",
        "        thresh (int): threshold for the number of bad predictions in confusion matrix\n",
        "\n",
        "    Returns:\n",
        "        classes (list): list of classes with the worst predictions\n",
        "    '''\n",
        "    classes = []\n",
        "    for i in range(len(class_ind)):\n",
        "        for j in range(len(class_ind)):\n",
        "            if i != j and (cm[i][j] > thresh or cm[j][i] > thresh):\n",
        "                print(i, j, cm[i][j], cm[j][i])\n",
        "                print('Between: {} and {}'.format(class_ind[i], class_ind[j]))\n",
        "                classes.append((i, j))\n",
        "    return classes"
      ],
      "metadata": {
        "id": "ufl9ItO2Z64P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lime_explain(model, class_labels, image):\n",
        "    '''\n",
        "    Explain the prediction of a model using LIME.\n",
        "\n",
        "    Args:\n",
        "        model (Sequential): model to use for prediction\n",
        "        class_labels (list): list of class labels\n",
        "        image (np.array): image to explain\n",
        "    '''\n",
        "    fig, ax = plt.subplots(2, 6, sharex='col', sharey='row')\n",
        "    fig.set_figwidth(20)\n",
        "    fig.set_figheight(16)\n",
        "\n",
        "    explainer = lime_image.LimeImageExplainer(random_state=42)\n",
        "    explanation = explainer.explain_instance(image[0], model.predict, top_labels=5, num_samples=1000, random_seed=42)\n",
        "    ax[0, 0].imshow(image[0])\n",
        "    ax[0, 0].set_title(class_labels[explanation.top_labels[0]])\n",
        "    for ind, i in enumerate(explanation.top_labels):\n",
        "        temp, mask = explanation.get_image_and_mask(i, positive_only=True, num_features=5, hide_rest=True)\n",
        "        ax[0,ind+1].imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
        "        ax[0,ind+1].set_title('{}'.format(class_labels[i]))\n",
        "\n"
      ],
      "metadata": {
        "id": "fst6Gg2Qoqk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(img_path):\n",
        "    '''\n",
        "    Show an image.\n",
        "\n",
        "    Args:\n",
        "        img_path (str): path to the image\n",
        "    '''\n",
        "    img_path = Image.open(img_path).convert(\"RGB\")\n",
        "    display(img_path)"
      ],
      "metadata": {
        "id": "CbNPMDTsqydB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_images(img_dir, filter_list, filtered_dir=None):\n",
        "    '''\n",
        "    Filter images in a directory.\n",
        "\n",
        "    Args:\n",
        "        img_dir (str): path to the directory containing the images\n",
        "        filter_list (list): list of images to filter out\n",
        "        filtered_dir (str): path to the directory to save the filtered images\n",
        "    '''\n",
        "    if filtered_dir is None:\n",
        "        for img in filter_list:\n",
        "            if os.path.isfile(img):\n",
        "                os.remove(img)\n",
        "    else:\n",
        "        for img in filter_list:\n",
        "            if os.path.isfile(img):\n",
        "                shutil.move(img, filtered_dir)"
      ],
      "metadata": {
        "id": "qcnzHpsmINLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "==== Functions below are for the future work of concat net ====="
      ],
      "metadata": {
        "id": "2iyxnSZUFIsb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04405701"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "class DualInputDataGenerator(Sequence):\n",
        "    def __init__(self, directory1, directory2, image_filenames, labels, batch_size, target_size=(331, 331), shuffle=True):\n",
        "        self.directory1 = directory1\n",
        "        self.directory2 = directory2\n",
        "        self.image_filenames = image_filenames\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.target_size = target_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.image_filenames))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_filenames = [self.image_filenames[i] for i in batch_indices]\n",
        "        batch_labels = [self.labels[i] for i in batch_indices]\n",
        "\n",
        "        images1 = []\n",
        "        images2 = []\n",
        "        for filename in batch_filenames:\n",
        "            img_path1 = os.path.join(self.directory1, filename)\n",
        "            img_path2 = os.path.join(self.directory2, filename)\n",
        "\n",
        "            img1 = image.load_img(img_path1, target_size=self.target_size)\n",
        "            img1 = image.img_to_array(img1)\n",
        "            img1 /= 255.0  # Rescale\n",
        "\n",
        "            img2 = image.load_img(img_path2, target_size=self.target_size)\n",
        "            img2 = image.img_to_array(img2)\n",
        "            img2 /= 255.0  # Rescale\n",
        "\n",
        "            images1.append(img1)\n",
        "            images2.append(img2)\n",
        "\n",
        "        # Convert to TensorFlow tensors\n",
        "        input_tensors = [tf.constant(np.array(images1), dtype=tf.float32), tf.constant(np.array(images2), dtype=tf.float32)]\n",
        "        label_tensor = tf.constant(np.array(batch_labels), dtype=tf.float32) # Labels are already one-hot, typically float\n",
        "\n",
        "        return input_tensors, label_tensor\n",
        "\n",
        "    @property\n",
        "    def output_signature(self):\n",
        "        # Define the expected output signature (inputs and labels)\n",
        "        input_signature = [\n",
        "            tf.TensorSpec(shape=(None, self.target_size[0], self.target_size[1], 3), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(None, self.target_size[0], self.target_size[1], 3), dtype=tf.float32)\n",
        "        ]\n",
        "        label_signature = tf.TensorSpec(shape=(None, self.labels.shape[1]), dtype=tf.float32) # Assuming labels are one-hot encoded\n",
        "\n",
        "        return input_signature, label_signature\n",
        "\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "def create_dual_input_generators(train_dir1, train_dir2, val_dir1, val_dir2, batch_size, input_size=[331, 331]):\n",
        "    # Assuming the subdirectories in train_dir1 and val_dir1 (or dir2) correspond to classes\n",
        "    # and the filenames within those subdirectories are the same for corresponding images\n",
        "\n",
        "    class_names = sorted(os.listdir(train_dir1))\n",
        "    class_indices = dict((name, index) for index, name in enumerate(class_names))\n",
        "\n",
        "    train_filenames = []\n",
        "    train_labels = []\n",
        "    val_filenames = []\n",
        "    val_labels = []\n",
        "\n",
        "    # Process training data\n",
        "    for class_name in class_names:\n",
        "        class_dir1 = os.path.join(train_dir1, class_name)\n",
        "        filenames = os.listdir(class_dir1)\n",
        "        train_filenames.extend([os.path.join(class_name, f) for f in filenames])\n",
        "        train_labels.extend([class_indices[class_name]] * len(filenames))\n",
        "\n",
        "    # Process validation data\n",
        "    for class_name in class_names:\n",
        "        class_dir1 = os.path.join(val_dir1, class_name)\n",
        "        filenames = os.listdir(class_dir1)\n",
        "        val_filenames.extend([os.path.join(class_name, f) for f in filenames])\n",
        "        val_labels.extend([class_indices[class_name]] * len(filenames))\n",
        "\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=len(class_names))\n",
        "    val_labels = tf.keras.utils.to_categorical(val_labels, num_classes=len(class_names))\n",
        "\n",
        "\n",
        "    train_generator = DualInputDataGenerator(\n",
        "        directory1=train_dir1,\n",
        "        directory2=train_dir2,\n",
        "        image_filenames=train_filenames,\n",
        "        labels=train_labels,\n",
        "        batch_size=batch_size,\n",
        "        target_size=input_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    test_generator = DualInputDataGenerator(\n",
        "        directory1=val_dir1,\n",
        "        directory2=val_dir2,\n",
        "        image_filenames=val_filenames,\n",
        "        labels=val_labels,\n",
        "        batch_size=batch_size, # You might want a different batch size for validation\n",
        "        target_size=input_size,\n",
        "        shuffle=False # No need to shuffle validation data\n",
        "    )\n",
        "\n",
        "    return train_generator, test_generator, class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d366f060"
      },
      "source": [
        "from tensorflow.keras.layers import Input, concatenate\n",
        "\n",
        "def define_concat_nasnetlarge_net(class_num):\n",
        "    # Define two separate input layers\n",
        "    input_1 = Input(shape=(331, 331, 3), name='input_1')\n",
        "    input_2 = Input(shape=(331, 331, 3), name='input_2')\n",
        "\n",
        "    # Define two NASNetLarge base models, one for each input with unique names\n",
        "    base_model_1 = NASNetLarge(weights='imagenet', include_top=False, input_shape=(331, 331, 3), name='nasnet_large_1')\n",
        "    base_model_2 = NASNetLarge(weights='imagenet', include_top=False, input_shape=(331, 331, 3), name='nasnet_large_2')\n",
        "\n",
        "    # Process each input through its respective base model\n",
        "    x1 = base_model_1(input_1)\n",
        "    x2 = base_model_2(input_2)\n",
        "\n",
        "    # Add GlobalAveragePooling2D to each branch\n",
        "    x1 = GlobalAveragePooling2D()(x1)\n",
        "    x2 = GlobalAveragePooling2D()(x2)\n",
        "\n",
        "    # Concatenate the outputs of the two branches\n",
        "    merged = concatenate([x1, x2])\n",
        "\n",
        "    # Add a dense layer for classification\n",
        "    prediction = Dense(class_num, activation='softmax')(merged)\n",
        "\n",
        "    # Create the model with two inputs and one output\n",
        "    model = Model(inputs=[input_1, input_2], outputs=prediction)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_accuracy(model, test_data):\n",
        "    pred = model.predict(test_data)\n",
        "    y_pred = pred.argmax(axis=1)\n",
        "    y_true = test_data.classes\n",
        "    acc = float(sum((y_pred == y_true))/len(y_pred))\n",
        "    error_index = np.where(y_pred != y_true)[0]\n",
        "    return acc, error_index"
      ],
      "metadata": {
        "id": "gmjYMBIgZwYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prepare_5_fold(data_list):\n",
        "    dict_by_breed = {}\n",
        "    split_dict = {}\n",
        "    for f in data_list:\n",
        "        dict_by_breed.setdefault(os.path.dirname(f), []).append(f)\n",
        "\n",
        "    for breed, fs in dict_by_breed.items():\n",
        "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        for i, (train_index, test_index) in enumerate(kf.split(fs)):\n",
        "            fs = np.array(fs)\n",
        "            sub_dict = split_dict.setdefault(i, {})\n",
        "            train, validation = train_test_split(fs[train_index], test_size=0.1, random_state=42)\n",
        "            sub_dict.setdefault('test', []).extend(fs[test_index])\n",
        "            sub_dict.setdefault('train', []).extend(train)\n",
        "            sub_dict.setdefault('validation', []).extend(validation)\n",
        "    return split_dict\n"
      ],
      "metadata": {
        "id": "j0rdiXd0svq7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}